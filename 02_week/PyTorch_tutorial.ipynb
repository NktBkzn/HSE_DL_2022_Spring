{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "PyTorch_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sCHX9H16JtY"
      },
      "source": [
        "Перед вами введение в синтаксис PyTorch, заимствованное с [официального сайта](https://pytorch.org/tutorials/index.html) фрэймворка\n",
        "\n",
        "По [данной](https://rickwierenga.com/blog/machine%20learning/numpy-vs-pytorch-linalg.html) ссылке находится также очень познавательная статья о сравнении библиотек `numpy` и `PyTorch` \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mXZZ0H3x7tO"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFwM_hDTx7tP"
      },
      "source": [
        "\n",
        "Introduction to PyTorch\n",
        "***********************\n",
        "\n",
        "Introduction to Torch's tensor library\n",
        "======================================\n",
        "\n",
        "All of deep learning is computations on tensors, which are\n",
        "generalizations of a matrix that can be indexed in more than 2\n",
        "dimensions. We will see exactly what this means in-depth later. First,\n",
        "let's look what we can do with tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kTj-BsBx7tR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807fed0f-74df-4294-e729-7583d4f04ccd"
      },
      "source": [
        "# Author: Robert Guthrie\n",
        "\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9e7ff74fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MEq_S1-x7tR"
      },
      "source": [
        "Creating Tensors\n",
        "~~~~~~~~~~~~~~~~\n",
        "\n",
        "Tensors can be created from Python lists with the torch.tensor()\n",
        "function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVMvJxY6x7tS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c9ecf4-90d8-4018-d5fb-b9e3acc554e9"
      },
      "source": [
        "# torch.tensor(data) creates a torch.Tensor object with the given data.\n",
        "V_data = [1., 2., 3.]\n",
        "V = torch.tensor(V_data)\n",
        "print(V)\n",
        "\n",
        "# Creates a matrix\n",
        "M_data = [[1., 2., 3.], [4., 5., 6]]\n",
        "M = torch.tensor(M_data)\n",
        "print(M)\n",
        "\n",
        "# Create a 3D tensor of size 2x2x2.\n",
        "T_data = [[[1., 2.], [3., 4.]],\n",
        "          [[5., 6.], [7., 8.]]]\n",
        "T = torch.tensor(T_data)\n",
        "print(T)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLtf4B59x7tS"
      },
      "source": [
        "What is a 3D tensor anyway? Think about it like this. If you have a\n",
        "vector, indexing into the vector gives you a scalar. If you have a\n",
        "matrix, indexing into the matrix gives you a vector. If you have a 3D\n",
        "tensor, then indexing into the tensor gives you a matrix!\n",
        "\n",
        "A note on terminology:\n",
        "when I say \"tensor\" in this tutorial, it refers\n",
        "to any torch.Tensor object. Matrices and vectors are special cases of\n",
        "torch.Tensors, where their dimension is 2 and 1 respectively. When I am\n",
        "talking about 3D tensors, I will explicitly use the term \"3D tensor\".\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1r2jYRcx7tT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d554eebe-7d5c-404c-b4f8-86534df5d315"
      },
      "source": [
        "# Index into V and get a scalar (0 dimensional tensor)\n",
        "print(V[0])\n",
        "# Get a Python number from it\n",
        "print(V[0].item())\n",
        "\n",
        "# Index into M and get a vector\n",
        "print(M[0])\n",
        "\n",
        "# Index into T and get a matrix\n",
        "print(T[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n",
            "1.0\n",
            "tensor([1., 2., 3.])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz_U9Irxx7tT"
      },
      "source": [
        "You can also create tensors of other data types. To create a tensor of integer types, try\n",
        "torch.tensor([[1, 2], [3, 4]]) (where all elements in the list are integers).\n",
        "You can also specify a data type by passing in ``dtype=torch.data_type``.\n",
        "Check the documentation for more data types, but\n",
        "Float and Long will be the most common.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApK31JZ1x7tU"
      },
      "source": [
        "You can create a tensor with random data and the supplied dimensionality\n",
        "with torch.randn()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agFQCe3wx7tU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2fe34d5-a3c4-4f55-ddf6-0d87f3434a30"
      },
      "source": [
        "x = torch.randn((3, 4, 5))\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.5256, -0.7502, -0.6540, -1.6095, -0.1002],\n",
            "         [-0.6092, -0.9798, -1.6091, -0.7121,  0.3037],\n",
            "         [-0.7773, -0.2515, -0.2223,  1.6871,  0.2284],\n",
            "         [ 0.4676, -0.6970, -1.1608,  0.6995,  0.1991]],\n",
            "\n",
            "        [[ 0.8657,  0.2444, -0.6629,  0.8073,  1.1017],\n",
            "         [-0.1759, -2.2456, -1.4465,  0.0612, -0.6177],\n",
            "         [-0.7981, -0.1316,  1.8793, -0.0721,  0.1578],\n",
            "         [-0.7735,  0.1991,  0.0457,  0.1530, -0.4757]],\n",
            "\n",
            "        [[-0.1110,  0.2927, -0.1578, -0.0288,  0.4533],\n",
            "         [ 1.1422,  0.2486, -1.7754, -0.0255, -1.0233],\n",
            "         [-0.5962, -1.0055,  0.4285,  1.4761, -1.7869],\n",
            "         [ 1.6103, -0.7040, -0.1853, -0.9962, -0.8313]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHRM4R9Ox7tU"
      },
      "source": [
        "Operations with Tensors\n",
        "~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "You can operate on tensors in the ways you would expect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80PODcu5x7tV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ec1b13-e634-40bb-8703-4901646e1428"
      },
      "source": [
        "x = torch.tensor([1., 2., 3.])\n",
        "y = torch.tensor([4., 5., 6.])\n",
        "z = x + y\n",
        "print(z)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9k3hXu8x7tV"
      },
      "source": [
        "See `the documentation <https://pytorch.org/docs/torch.html>`__ for a\n",
        "complete list of the massive number of operations available to you. They\n",
        "expand beyond just mathematical operations.\n",
        "\n",
        "One helpful operation that we will make use of later is concatenation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rum2GbkZx7tV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301238d0-6b74-4b4a-ce07-81e0cab8bba5"
      },
      "source": [
        "# By default, it concatenates along the first axis (concatenates rows)\n",
        "x_1 = torch.randn(2, 5)\n",
        "y_1 = torch.randn(3, 5)\n",
        "z_1 = torch.cat([x_1, y_1])\n",
        "print(z_1)\n",
        "\n",
        "# Concatenate columns:\n",
        "x_2 = torch.randn(2, 3)\n",
        "y_2 = torch.randn(2, 5)\n",
        "# second arg specifies which axis to concat along\n",
        "z_2 = torch.cat([x_2, y_2], 1)\n",
        "print(z_2)\n",
        "\n",
        "# If your tensors are not compatible, torch will complain.  Uncomment to see the error\n",
        "# torch.cat([x_1, x_2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8029,  0.2366,  0.2857,  0.6898, -0.6331],\n",
            "        [ 0.8795, -0.6842,  0.4533,  0.2912, -0.8317],\n",
            "        [-0.5525,  0.6355, -0.3968, -0.6571, -1.6428],\n",
            "        [ 0.9803, -0.0421, -0.8206,  0.3133, -1.1352],\n",
            "        [ 0.3773, -0.2824, -2.5667, -1.4303,  0.5009]])\n",
            "tensor([[ 0.5438, -0.4057,  1.1341, -0.1473,  0.6272,  1.0935,  0.0939,  1.2381],\n",
            "        [-1.1115,  0.3501, -0.7703, -1.3459,  0.5119, -0.6933, -0.1668, -0.9999]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S_W5-IXZ_y6"
      },
      "source": [
        "__Tensor__ -- это такой же массив, как и в __numpy.array__, размерность и тип данных которого мы можем задать. Tensor в отличие от numpy.array может вычисляться на __GPU__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZQqjAouZ_y6"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj4mRT0wZ_y8"
      },
      "source": [
        "N = 100\n",
        "D_in = 50\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "x = np.random.randn(N, D_in)\n",
        "x_torch = torch.randn(N, D_in, device=device, dtype=dtype)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKwslA-KZ_y8",
        "outputId": "0c20aa9c-b56b-4c29-b547-5e4a2e604337"
      },
      "source": [
        "x"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.2638648 , -0.03437633, -0.55319802, ..., -0.41123931,\n",
              "         0.06231457, -0.0491905 ],\n",
              "       [-0.76795562,  0.53951991,  2.51172327, ...,  0.36734818,\n",
              "        -1.46713249,  0.3205242 ],\n",
              "       [ 0.26242508,  1.07044624, -0.24636752, ..., -2.06805073,\n",
              "        -1.19888866, -0.87439356],\n",
              "       ...,\n",
              "       [ 1.12794418,  0.03246402, -0.84432362, ..., -0.04745605,\n",
              "        -0.8425033 , -0.83633349],\n",
              "       [-0.2640023 , -0.9578809 , -0.26502743, ...,  0.12074524,\n",
              "        -0.35128336, -0.63252617],\n",
              "       [ 1.21576708,  1.23577092, -0.60666519, ..., -0.7880213 ,\n",
              "         1.49426713,  0.80292239]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtHuXc3oZ_y-",
        "outputId": "2d059914-362c-4c6e-bda8-61b2ecc68090"
      },
      "source": [
        "x_torch"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4175, -0.2127, -0.8400,  ...,  0.0571,  0.9055,  1.0463],\n",
              "        [-0.5206,  1.3548,  0.2352,  ...,  0.8956,  0.1675,  0.7514],\n",
              "        [ 2.4142,  1.0206, -0.4405,  ...,  2.3403, -0.6116,  0.8160],\n",
              "        ...,\n",
              "        [-0.4154, -0.2963,  0.5661,  ...,  0.7328, -0.2776,  0.3650],\n",
              "        [-1.7876, -0.1829,  1.5955,  ...,  0.5376, -1.7307,  1.5791],\n",
              "        [ 0.4305,  1.4203,  0.2883,  ...,  0.7285, -0.4101, -0.4788]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcMpqZlfklWx",
        "outputId": "38335f83-4c0a-4e75-a6bf-b5bf0bf77d0b"
      },
      "source": [
        "np.ones((N, D_in))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       ...,\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.],\n",
              "       [1., 1., 1., ..., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szfEFIIVZ_y-",
        "outputId": "9385a08c-6426-4639-c6b3-c7b5ea5b69b0"
      },
      "source": [
        "x_torch = torch.Tensor(np.ones((N, D_in)))\n",
        "x_torch"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        ...,\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "        [1., 1., 1.,  ..., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bojAY0khbQ5n"
      },
      "source": [
        "На [странице](https://pytorch.org/docs/stable/tensors.html) приведено описания различных численных форматов `torch.Tensor`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUgf-nbeZ_y_",
        "outputId": "fffcd14c-e13e-4775-cdf9-7b9ef37f653a"
      },
      "source": [
        "x_torch = torch.FloatTensor([1, 2, 3])\n",
        "x_torch"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHa1ITl_Z_zA"
      },
      "source": [
        "x1 = torch.IntTensor([1, 2, 3])\n",
        "x2 = torch.FloatTensor([3, 4, 5])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs3M8Sifk0-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8c6f25-a661-42a8-dc1a-7142183d64a5"
      },
      "source": [
        "x1, x2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3], dtype=torch.int32), tensor([3., 4., 5.]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XN-1y_GZ_zB"
      },
      "source": [
        "В PyTorch можно найти много операций, которые похожи на то, что есть в numpy :\n",
        "```\n",
        "- torch.add (np.add) -> сложение тензоров (поэлементное)\n",
        "- torch.sub (np.subtract) -> вычитание (поэлементное)\n",
        "- torch.mul (np.multiply) -> умнажение скаляров / матриц (поэлементное)\n",
        "- torch.mm (np.matmul) -> перемножение матриц\n",
        "- torch.ones (np.ones) -> создание тензора из единиц\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGIRBUF4bUBO"
      },
      "source": [
        "Давайте попробуем вышепересчисленные операции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PF3LZ9gmHya",
        "outputId": "8e5b65fa-8a84-41ad-c5b1-068fa4699867"
      },
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "b = torch.ones_like(a)\n",
        "print(a, b)\n",
        "torch.add(a, b), a.add(b)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) tensor([1, 1, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2, 3, 4]), tensor([2, 3, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzdwnhQfZ_zB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cedae0b1-2870-48ad-8291-30eed9a10ee4"
      },
      "source": [
        "x1 = torch.FloatTensor([[1, 2, 3], [4, 5, 6]])\n",
        "x1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBM-74viZ_zC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac8c266-5b30-42e7-9d1e-bf2fe2e6b146"
      },
      "source": [
        "x2 = torch.FloatTensor([[7, 8], [9, 1], [2, 3]])\n",
        "x2"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7., 8.],\n",
              "        [9., 1.],\n",
              "        [2., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J0qOFUPZ_zC",
        "outputId": "1c512c00-0c0a-45f5-c4f3-6b81a900cfc5"
      },
      "source": [
        "out = torch.mm(x1, x2)\n",
        "out"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[31., 19.],\n",
              "        [85., 55.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWf0t6QTREH5",
        "outputId": "827ba864-2008-4761-cd09-08162ca6fb8e"
      },
      "source": [
        "torch.ones((3, 3))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "walRvfIVRG87",
        "outputId": "4bc5039d-326c-40a6-85bc-a7522e947268"
      },
      "source": [
        "print(torch.ones_like(x1))\n",
        "print()\n",
        "print(torch.ones_like(x2))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Bgo2ILx7tW"
      },
      "source": [
        "Reshaping Tensors\n",
        "~~~~~~~~~~~~~~~~~\n",
        "\n",
        "Use the .view() method to reshape a tensor. This method receives heavy\n",
        "use, because many neural network components expect their inputs to have\n",
        "a certain shape. Often you will need to reshape before passing your data\n",
        "to the component.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V8gCNAlx7tW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1e99b6-3219-4b3c-ed58-370d002eb778"
      },
      "source": [
        "x = torch.randn(2, 3, 4)\n",
        "print(x, '\\n\\n')\n",
        "print(x.view(2, 12))  # Reshape to 2 rows, 12 columns\n",
        "# Same as above.  If one of the dimensions is -1, its size can be inferred\n",
        "print(x.view(2, -1))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0286, -0.8836,  0.0909, -0.4940],\n",
            "         [ 1.3182, -0.0845,  1.1725, -0.7763],\n",
            "         [-2.6301, -1.7034,  0.4825, -1.0118]],\n",
            "\n",
            "        [[-0.5213, -0.6625, -0.0301,  0.4308],\n",
            "         [-1.3608, -1.6181, -0.6584,  1.5646],\n",
            "         [ 1.4422, -0.3800,  0.0816,  1.5062]]]) \n",
            "\n",
            "\n",
            "tensor([[-0.0286, -0.8836,  0.0909, -0.4940,  1.3182, -0.0845,  1.1725, -0.7763,\n",
            "         -2.6301, -1.7034,  0.4825, -1.0118],\n",
            "        [-0.5213, -0.6625, -0.0301,  0.4308, -1.3608, -1.6181, -0.6584,  1.5646,\n",
            "          1.4422, -0.3800,  0.0816,  1.5062]])\n",
            "tensor([[-0.0286, -0.8836,  0.0909, -0.4940,  1.3182, -0.0845,  1.1725, -0.7763,\n",
            "         -2.6301, -1.7034,  0.4825, -1.0118],\n",
            "        [-0.5213, -0.6625, -0.0301,  0.4308, -1.3608, -1.6181, -0.6584,  1.5646,\n",
            "          1.4422, -0.3800,  0.0816,  1.5062]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN2Ym9jPZ_zD"
      },
      "source": [
        "```\n",
        "- torch.reshape или tensor.view (где tensor-это объект torch.tensor) -> изменения порядка элементов в тензоре, не путать с транспонированием.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gB1HMmUlUa4",
        "outputId": "5cc5ee17-a8aa-4a44-f293-6159a124573f"
      },
      "source": [
        "print(x1, '\\n\\n')\n",
        "x1.t()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]]) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 4.],\n",
              "        [2., 5.],\n",
              "        [3., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBWetyXVPeJy",
        "outputId": "272f826a-b55f-4e63-f5d3-00bde5a5e428"
      },
      "source": [
        "torch.reshape(x1, (-1, 2))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00DJZIqPP1py",
        "outputId": "65c5f82f-c34e-4e6b-b27d-04d31ad43116"
      },
      "source": [
        "x1.view((-1, 2))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZjgQ2LgQCkI",
        "outputId": "6bbca5b0-022e-4bef-8108-2fb22de750e8"
      },
      "source": [
        "x1 = x1.reshape_as(x2)\n",
        "x1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jui05AGQJ-_",
        "outputId": "3dba4148-930f-4583-e169-2c8eb24ffd67"
      },
      "source": [
        "x1 = x1.type(torch.int)\n",
        "\n",
        "print(f'x1 type: {x1.dtype} \\nx2 type: {x2.dtype} \\n\\n')\n",
        "x1 + x2"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 type: torch.int32 \n",
            "x2 type: torch.float32 \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8., 10.],\n",
              "        [12.,  5.],\n",
              "        [ 7.,  9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KrNUohPx7tX"
      },
      "source": [
        "Computation Graphs and Automatic Differentiation\n",
        "================================================\n",
        "\n",
        "The concept of a computation graph is essential to efficient deep\n",
        "learning programming, because it allows you to not have to write the\n",
        "back propagation gradients yourself. A computation graph is simply a\n",
        "specification of how your data is combined to give you the output. Since\n",
        "the graph totally specifies what parameters were involved with which\n",
        "operations, it contains enough information to compute derivatives. This\n",
        "probably sounds vague, so let's see what is going on using the\n",
        "fundamental flag ``requires_grad``.\n",
        "\n",
        "First, think from a programmers perspective. What is stored in the\n",
        "torch.Tensor objects we were creating above? Obviously the data and the\n",
        "shape, and maybe a few other things. But when we added two tensors\n",
        "together, we got an output tensor. All this output tensor knows is its\n",
        "data and shape. It has no idea that it was the sum of two other tensors\n",
        "(it could have been read in from a file, it could be the result of some\n",
        "other operation, etc.)\n",
        "\n",
        "**Important:** If ``requires_grad=True``, the Tensor object keeps track of how it was\n",
        "created. Let's see it in action.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isr7X41lx7tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ef7f98-e0b3-4650-d708-ba2fa4e25feb"
      },
      "source": [
        "# Tensor factory methods have a ``requires_grad`` flag\n",
        "x = torch.tensor([1., 2., 3], requires_grad=True)\n",
        "\n",
        "# With requires_grad=True, you can still do all the operations you previously\n",
        "# could\n",
        "y = torch.tensor([4., 5., 6], requires_grad=True)\n",
        "t = x + y\n",
        "print(t)\n",
        "\n",
        "# BUT t knows something extra.\n",
        "print(t.grad_fn)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7f9e78477390>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6-ftP1zx7tY"
      },
      "source": [
        "So Tensors know what created them. t knows that it wasn't read in from\n",
        "a file, it wasn't the result of a multiplication or exponential or\n",
        "whatever. And if you keep following t.grad_fn, you will find yourself at\n",
        "x and y.\n",
        "\n",
        "But how does that help us compute a gradient?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX12REJvx7tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80f3e6a-e50a-42c2-ca09-8b62b06fb43c"
      },
      "source": [
        "# Let's sum up all the entries in z\n",
        "s = t.sum()\n",
        "print(s)\n",
        "print(s.grad_fn)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(21., grad_fn=<SumBackward0>)\n",
            "<SumBackward0 object at 0x7f9e78eccd10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MNxe9dyx7tZ"
      },
      "source": [
        "So now, what is the derivative of this sum with respect to the first\n",
        "component of x? In math, we want\n",
        "\n",
        "\\begin{align}\\frac{\\partial s}{\\partial x_0}\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "Well, s knows that it was created as a sum of the tensor z. z knows\n",
        "that it was the sum x + y. So\n",
        "\n",
        "\\begin{align}s = \\overbrace{x_0 + y_0}^\\text{$z_0$} + \\overbrace{x_1 + y_1}^\\text{$z_1$} + \\overbrace{x_2 + y_2}^\\text{$z_2$}\\end{align}\n",
        "\n",
        "And so s contains enough information to determine that the derivative\n",
        "we want is 1!\n",
        "\n",
        "Of course this glosses over the challenge of how to actually compute\n",
        "that derivative. The point here is that s is carrying along enough\n",
        "information that it is possible to compute it. In reality, the\n",
        "developers of Pytorch program the sum() and + operations to know how to\n",
        "compute their gradients, and run the back propagation algorithm. An\n",
        "in-depth discussion of that algorithm is beyond the scope of this\n",
        "tutorial.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDJf9yBtx7tZ"
      },
      "source": [
        "Let's have Pytorch compute the gradient, and see that we were right:\n",
        "(note if you run this block multiple times, the gradient will increment.\n",
        "That is because Pytorch *accumulates* the gradient into the .grad\n",
        "property, since for many models this is very convenient.)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rThnkYQ2ltsV",
        "outputId": "5c81fe21-86b6-40bf-dc02-a1013da536c3"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8g44fx-l9-s"
      },
      "source": [
        "# optimizer.zero_grad()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTkZEhvcx7tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779c773c-60db-46f7-bcb1-b2c581c0285b"
      },
      "source": [
        "# calling .backward() on any variable will run backprop, starting from it.\n",
        "s.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb4tsQyyx7ta"
      },
      "source": [
        "Understanding what is going on in the block below is crucial for being a\n",
        "successful programmer in deep learning.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTG8uGs5x7ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41eb5e6-90c9-41db-ac30-7ee95fbd2256"
      },
      "source": [
        "x = torch.randn(2, 2)\n",
        "y = torch.randn(2, 2)\n",
        "# By default, user created Tensors have ``requires_grad=False``\n",
        "print(x.requires_grad, y.requires_grad)\n",
        "z = x + y\n",
        "# So you can't backprop through z\n",
        "print(z.grad_fn)\n",
        "\n",
        "# ``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
        "# flag in-place. The input flag defaults to ``True`` if not given.\n",
        "x = x.requires_grad_()\n",
        "y = y.requires_grad_()\n",
        "# z contains enough information to compute gradients, as we saw above\n",
        "z = x + y\n",
        "print(z.grad_fn)\n",
        "# If any input to an operation has ``requires_grad=True``, so will the output\n",
        "print(z.requires_grad)\n",
        "\n",
        "# Now z has the computation history that relates itself to x and y\n",
        "# Can we just take its values, and **detach** it from its history?\n",
        "new_z = z.detach()\n",
        "\n",
        "# ... does new_z have information to backprop to x and y?\n",
        "# NO!\n",
        "print(new_z.grad_fn)\n",
        "# And how could it? ``z.detach()`` returns a tensor that shares the same storage\n",
        "# as ``z``, but with the computation history forgotten. It doesn't know anything\n",
        "# about how it was computed.\n",
        "# In essence, we have broken the Tensor away from its past history"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False False\n",
            "None\n",
            "<AddBackward0 object at 0x7f9e7844fe10>\n",
            "True\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "x = torch.ones([10], requires_grad=True)\n",
        "# plt.plot(x)  # doesn't work\n",
        "plt.plot(x.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "iefsSCl7E756",
        "outputId": "609a41ec-f1bb-427d-e603-92cc9805becd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9e78415e90>]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmn3BWeax7tb"
      },
      "source": [
        "You can also stop autograd from tracking history on Tensors\n",
        "with ``.requires_grad=True`` by wrapping the code block in\n",
        "``with torch.no_grad():``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXKOmpCNx7tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d449ad-acf2-40cc-8b3d-55b3f70a6198"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Зачем нужно делать zero_grad()?\n",
        "\n",
        "If a tensor already has grad attribute, e.g from the previous call to backward, subsequent calls will add to the value of this attribute. So, if you, e.g, backward() in a loop, you need to explicitely set grad to zero each time."
      ],
      "metadata": {
        "id": "1bGs5lkPEZVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "x.grad is None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bSMZZJfEZqn",
        "outputId": "4d5013a6-3418-4002-a727-83905b8c661a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = x * 2\n",
        "b = x * 3\n",
        "y = a + b  # == x * 5\n",
        "# in this case y.backward() is the same as\n",
        "a.backward()\n",
        "b.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6KBRLqpEdQH",
        "outputId": "dc770437-f7b4-4f92-d956-5fe424bb92c0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "print(x.grad is None)\n",
        "a = x * 2\n",
        "b = x * 3\n",
        "a.backward()\n",
        "print(x.grad)\n",
        "b.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obbwugToEfJX",
        "outputId": "f360a1b3-2dc5-43e2-d5d4-43869d81092e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "tensor([2.])\n",
            "tensor([5.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "for i in range(2):\n",
        "    y = x * 2\n",
        "    y.backward()\n",
        "    print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_287ZzfEp-T",
        "outputId": "94c5e93b-eff0-48b9-ffd7-81dd47ec302d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.])\n",
            "tensor([4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "for i in range(2):\n",
        "    y = x * 2\n",
        "    y.backward()\n",
        "    print(x.grad)\n",
        "    x.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67FKg5awEtVV",
        "outputId": "e4a2d966-46cc-4145-bde9-a2de8e1ace79"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.])\n",
            "tensor([2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NKRBko_2Ew2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}