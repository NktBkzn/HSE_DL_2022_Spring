{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weight_initialization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "feeB7xwujYag"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Set seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Scheduler import\n",
        "from torch.optim.lr_scheduler import StepLR\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZzo8z_qjv16"
      },
      "source": [
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlUkSjwrjzWJ"
      },
      "source": [
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TuqfK4tk8HC"
      },
      "source": [
        " Веса инициализируются в момент опсиания архитектуры сети.\n",
        " Все возможные варианты инициализации весов приведены в официальной [документации](https://pytorch.org/docs/stable/nn.init.html). В примере ниже веса инициализируются методом Ксавье, что соотвествует использованию `tanh` в качестве функции активации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_qI_70vl7sn"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGOi0Ot9mA7i"
      },
      "source": [
        "%cd /content/gdrive/My Drive/HSE_DL_2021/04_week"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjHL4q04ljut"
      },
      "source": [
        "from IPython import display\n",
        "display.Image('images/xavier.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMoQXscbj1jV"
      },
      "source": [
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, act_type='relu', init_type='he'):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
        "        \n",
        "        # Non-linearity\n",
        "        if act_type == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif act_type == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif act_type == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        else:\n",
        "            print('This kind of activation is not supported in this net')\n",
        "\n",
        "        # Linear function (readout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
        "        \n",
        "        # Linear weight, W,  Y = WX + B\n",
        "        if init_type == 'xavier':\n",
        "            nn.init.xavier_normal_(self.fc1.weight)\n",
        "            nn.init.xavier_normal_(self.fc2.weight)\n",
        "        elif init_type == 'he':\n",
        "            nn.init.kaiming_normal_(self.fc1.weight)\n",
        "            nn.init.kaiming_normal_(self.fc2.weight)\n",
        "        else:\n",
        "            print('This kind of initialization is not supported in this net')\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity\n",
        "        out = self.activation(out)\n",
        "        # Linear function (readout)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROlg-F2r37mt"
      },
      "source": [
        "a = torch.empty(3,3)\n",
        "print(a)\n",
        "nn.init.xavier_normal_(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui7hsuHHj3vk"
      },
      "source": [
        "'''\n",
        "STEP 4: INSTANTIATE BASE PARAMETERS\n",
        "'''\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EsRaDJXj5ww"
      },
      "source": [
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZBW9VhAj5zb"
      },
      "source": [
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8lyIz-dj519"
      },
      "source": [
        "'''\n",
        "STEP 7: INSTANTIATE STEP LEARNING SCHEDULER CLASS\n",
        "'''\n",
        "# step_size: at how many multiples of epoch you decay\n",
        "# step_size = 1, after every 1 epoch, new_lr = lr*gamma \n",
        "# step_size = 2, after every 2 epoch, new_lr = lr*gamma \n",
        "\n",
        "# gamma = decaying factor\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.96)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0kbBY_IjgOJ"
      },
      "source": [
        "'''\n",
        "STEP 8: TRAIN THE MODEL\n",
        "'''\n",
        "def model_train(model, criterion, optimizer, scheduler, train_loader, test_loader):\n",
        "    iter = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        # Print Learning Rate\n",
        "        print('Epoch:', epoch,'LR:', scheduler.get_last_lr()[0])\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # Load images as tensors with gradient accumulation abilities\n",
        "            images = images.view(-1, 28*28).requires_grad_()\n",
        "\n",
        "            # Clear gradients w.r.t. parameters\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass to get output/logits\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calculate Loss: softmax --> cross entropy loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Getting gradients w.r.t. parameters\n",
        "            loss.backward()\n",
        "\n",
        "            # Updating parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            iter += 1\n",
        "\n",
        "            if iter % 500 == 0:\n",
        "                # Calculate Accuracy         \n",
        "                correct = 0\n",
        "                total = 0\n",
        "                # Iterate through test dataset\n",
        "                for images, labels in test_loader:\n",
        "                    # Load images to a Torch Variable\n",
        "                    images = images.view(-1, 28*28)\n",
        "\n",
        "                    # Forward pass only to get logits/output\n",
        "                    outputs = model(images)\n",
        "\n",
        "                    # Get predictions from the maximum value\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                    # Total number of labels\n",
        "                    total += labels.size(0)\n",
        "\n",
        "                    # Total correct predictions\n",
        "                    correct += (predicted.type(torch.FloatTensor).cpu() == labels.type(torch.FloatTensor)).sum()\n",
        "\n",
        "                accuracy = 100. * correct.item() / total\n",
        "\n",
        "                # Print Loss\n",
        "                print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n",
        "\n",
        "        # Decay Learning Rate\n",
        "        scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob0e_jsnpKzy"
      },
      "source": [
        "## ReLU + Xavier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evQsgeH9sw2u"
      },
      "source": [
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim, act_type='relu', init_type='xavier')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.96)\n",
        "\n",
        "model_train(model, criterion, optimizer, scheduler, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjFwvc0bpPP2"
      },
      "source": [
        "## Sigmoid + Xavier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paAEuXIGkWMl"
      },
      "source": [
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim, act_type='sigmoid', init_type='xavier')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.96)\n",
        "\n",
        "model_train(model, criterion, optimizer, scheduler, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEAo35ujpJLA"
      },
      "source": [
        "## Tanh + Xavier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy0bTd0Cn_Z1"
      },
      "source": [
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim, act_type='tanh', init_type='xavier')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.96)\n",
        "\n",
        "model_train(model, criterion, optimizer, scheduler, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwd-6YU-o_GF"
      },
      "source": [
        "## ReLU + He\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iAYFRNDo_RU"
      },
      "source": [
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim, act_type='relu', init_type='he')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.96)\n",
        "\n",
        "model_train(model, criterion, optimizer, scheduler, train_loader, test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPXZvg9ko_dg"
      },
      "source": [
        "## Sigmoid + He\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p61REhuUo_op"
      },
      "source": [
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim, act_type='sigmoid', init_type='he')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.96)\n",
        "\n",
        "model_train(model, criterion, optimizer, scheduler, train_loader, test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8vADfkdo_1c"
      },
      "source": [
        "## Tanh + He\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJQroB9Wo_-I"
      },
      "source": [
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim, act_type='tanh', init_type='he')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.96)\n",
        "\n",
        "model_train(model, criterion, optimizer, scheduler, train_loader, test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3YnfPv9uIuJ"
      },
      "source": [
        "[Источник](https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/weight_initialization_activation_functions/) ноутбука"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Rhw8wjuQJc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}