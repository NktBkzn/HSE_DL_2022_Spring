#  Deep Learning HSE весна 2022


### Полезные ресурсы
* Если вы хотите скачать из репозитория конкретную папку или файл, просто вставьте ссылку на неё в [сервис для скачивания](https://minhaskamal.github.io/DownGit/#/home?url=). 

### Домашние задания
| №      | Название                               | Задание                                  | Срок     |
| :---:  |:-------------------------------------  | :--------------------------------------  | :------: |
| 1      | HW01_intro_classification_pytorch.ipynb| Внизу ноутбука расписано по пунктам      | 22.04.22 |
| 2      | HW02_gradient.ipynb                    | Реализовать градиентный спуск            | 29.04.22 |


[Таблица](https://docs.google.com/spreadsheets/d/1jjvWV7kHw88akCuMFbbAcNsnrUdGH530hUTAhhm182w/edit#gid=0) с результатами сдачи

### Программа курса + ссылки на хорошие материалы по теме
01. Введение в нейросети
02. Адаптивные варианты градиентного спуска
   - [Почему momentum работает](https://distill.pub/2017/momentum/)
   - [Bias correction in Adam](https://www.youtube.com/watch?v=-0ZMU-gnm2g)
   - Новомодный optimizer [AdamW](https://arxiv.org/pdf/1711.05101.pdf)
   - [Cyclical Learning Rate](https://medium.com/swlh/cyclical-learning-rates-the-ultimate-guide-for-setting-learning-rates-for-neural-networks-3104e906f0ae)
03. Алгоритм обратного распространения ошибки
04. Инструменты в Python для обучения нейронных сетей
   - [Dataloader/Dateset в PyTorch](https://discuss.pytorch.org/t/making-iterable-objects-using-torch-utils-data-dataloader/16681/2)
   - [Weight initialization](https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/weight_initialization_activation_functions/)
   - [Python generators](https://realpython.com/introduction-to-python-generators/)
   - [Iterators vs Generators](https://stackoverflow.com/questions/2776829/difference-between-pythons-generators-and-iterators)
05. Батч-нормализация. Инициализация. Эвристики для обучения сетей
   - [BatchNorm explained](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338)
   - [Custom weight decay](https://raberrytv.wordpress.com/2017/10/29/pytorch-weight-decay-made-easy/)
   - [Inverted dropout](https://www.coursera.org/lecture/deep-neural-network/dropout-regularization-eM33A)